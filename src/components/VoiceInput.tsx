import { useState, useRef } from "react";
import { Button } from "@/components/ui/button";
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from "@/components/ui/card";
import { Mic, Square, Volume2 } from "lucide-react";
import { useToast } from "@/hooks/use-toast";
import { supabase } from "@/integrations/supabase/client";

interface VoiceInputProps {
  onTranscript: (transcript: string) => void;
  loading?: boolean;
}

const VoiceInput = ({ onTranscript, loading = false }: VoiceInputProps) => {
  const [isRecording, setIsRecording] = useState(false);
  const [transcript, setTranscript] = useState("");
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const { toast } = useToast();

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus') ? 'audio/webm;codecs=opus' : 'audio/webm';
      const mediaRecorder = new MediaRecorder(stream, { mimeType });
      mediaRecorderRef.current = mediaRecorder;

      const audioChunks: Blob[] = [];
      
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) audioChunks.push(event.data);
      };

      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
        const toBase64 = (blob: Blob) => new Promise<string>((resolve, reject) => {
          const reader = new FileReader();
          reader.onloadend = () => resolve((reader.result as string).split(',')[1]);
          reader.onerror = reject;
          reader.readAsDataURL(blob);
        });

        try {
          toast({ title: 'Transcrevendo √°udio...', description: 'Aguarde alguns instantes.' });
          const base64Audio = await toBase64(audioBlob);
          
          // Use Supabase client to call edge function
          const { data, error } = await supabase.functions.invoke('voice-to-text', {
            body: { audio: base64Audio }
          });

          if (error) throw new Error(error.message);
          if (!data.text) throw new Error('Falha na transcri√ß√£o');

          setTranscript(data.text);
          onTranscript(data.text);
        } catch (err: any) {
          const fallback = 'Transcri√ß√£o indispon√≠vel no momento. Descreva manualmente os dados do cliente.';
          setTranscript(fallback);
          toast({ title: 'Falha na transcri√ß√£o', description: err.message, variant: 'destructive' });
        }
        
        // Stop all tracks to release microphone
        stream.getTracks().forEach(track => track.stop());
      };

      mediaRecorder.start();
      setIsRecording(true);
      
      toast({
        title: "Grava√ß√£o iniciada",
        description: "Fale sobre o perfil do seu cliente...",
      });
    } catch (error) {
      toast({
        title: "Erro no microfone",
        description: "N√£o foi poss√≠vel acessar o microfone. Verifique as permiss√µes.",
        variant: "destructive",
      });
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      
      toast({
        title: "Grava√ß√£o finalizada",
        description: "Processando seu √°udio...",
      });
    }
  };

  return (
    <Card className="w-full max-w-2xl mx-auto shadow-medium bg-gradient-card">
      <CardHeader className="text-center">
        <CardTitle className="flex items-center justify-center gap-2">
          <Volume2 className="h-6 w-6 text-primary" />
          Entrada por Voz
        </CardTitle>
        <CardDescription>
          Descreva o perfil do seu cliente falando naturalmente
        </CardDescription>
      </CardHeader>
      <CardContent className="space-y-6">
        <div className="flex flex-col items-center space-y-4">
          <div className={`p-8 rounded-full ${isRecording ? 'bg-destructive/20 animate-pulse' : 'bg-primary/20'} transition-all duration-300`}>
            <Mic className={`h-16 w-16 ${isRecording ? 'text-destructive' : 'text-primary'}`} />
          </div>
          
          <div className="flex gap-4">
            {!isRecording ? (
              <Button
                onClick={startRecording}
                variant="hero"
                size="xl"
                disabled={loading}
              >
                <Mic className="h-5 w-5 mr-2" />
                Iniciar Grava√ß√£o
              </Button>
            ) : (
              <Button
                onClick={stopRecording}
                variant="destructive"
                size="xl"
              >
                <Square className="h-5 w-5 mr-2" />
                Parar Grava√ß√£o
              </Button>
            )}
          </div>

          {isRecording && (
            <p className="text-sm text-muted-foreground text-center animate-pulse">
              üé§ Gravando... Fale sobre idade, profiss√£o, renda, dependentes e sa√∫de do cliente
            </p>
          )}
        </div>

        {transcript && (
          <div className="mt-6 p-4 bg-muted/50 rounded-lg border-l-4 border-primary">
            <h4 className="font-semibold mb-2 text-primary">Transcri√ß√£o:</h4>
            <p className="text-sm text-muted-foreground leading-relaxed">
              {transcript}
            </p>
          </div>
        )}

        <div className="text-xs text-muted-foreground text-center space-y-1">
          <p>üí° <strong>Dica:</strong> Mencione idade, sexo, profiss√£o, renda mensal, dependentes, d√≠vidas e estado de sa√∫de</p>
          <p>üé§ <strong>Transcri√ß√£o Autom√°tica:</strong> Powered by OpenAI Whisper</p>
        </div>
      </CardContent>
    </Card>
  );
};

export default VoiceInput;